{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to create 3 parallel autoencoder networks for 3 axis IMU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "# import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1548000, 15)\n",
      "(193600, 15)\n"
     ]
    }
   ],
   "source": [
    "reqd_len = 100\n",
    "channels = 3\n",
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, mode = 'test', transform = None):\n",
    "        if mode == 'train' : \n",
    "            self.df = pd.read_csv('../data/train.csv', header = None)\n",
    "        elif mode == 'test' : \n",
    "            self.df = pd.read_csv('../data/test.csv', header = None)\n",
    "        self.transform = transform\n",
    "        print(self.df.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.df.iloc[idx : idx + reqd_len, : channels].values\n",
    "        x = x.astype('float')\n",
    "        assert(x.shape == (reqd_len, channels))\n",
    "        return x\n",
    "        \n",
    "train_dataset = IMUDataset(mode = 'train')\n",
    "test_dataset = IMUDataset(mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_indices = [(i * reqd_len) for i in range(len(train_dataset) // reqd_len)]\n",
    "test_indices = [(i * reqd_len) for i in range(len(test_dataset) // reqd_len)]\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size = batch_size, sampler = SubsetRandomSampler(train_indices), drop_last = True)\n",
    "trainloader2 = DataLoader(train_dataset, batch_size = 1, sampler = SubsetRandomSampler(train_indices), drop_last = True)\n",
    "testloader2 = DataLoader(test_dataset, batch_size = 1, sampler = SubsetRandomSampler(test_indices), drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x2, y2, z2 = next(iter(trainloader2))\n",
    "# print(x2.shape)\n",
    "# signal = signal.detach().numpy()\n",
    "# signal = np.transpose(signal).reshape(-1)\n",
    "# t = range(150)\n",
    "# plt.plot(t, signal[150 : 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for xavier initialization of network\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "class AutoEncoder(nn.Module) :\n",
    "    def __init__(self) : \n",
    "        super(AutoEncoder, self).__init__()\n",
    "        # defining layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 3, out_channels = 2, kernel_size = 5),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv1d(in_channels = 2, out_channels = 1, kernel_size = 5),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 5),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 5),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels = 1, out_channels = 1, kernel_size = 5),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose1d(in_channels = 1, out_channels = 1, kernel_size = 5),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose1d(in_channels = 1, out_channels = 2, kernel_size = 5),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose1d(in_channels = 2, out_channels = 3, kernel_size = 5),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(84, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 4)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, encode = False, classify = False) :\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        features = self.encoder(x)\n",
    "        \n",
    "        if encode and not classify:\n",
    "            return features\n",
    "        elif not encode and classify :\n",
    "            features = features.view(-1, 134)\n",
    "            return self.classifier(features)\n",
    "        else : \n",
    "            return self.decoder(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net = AutoEncoder()\n",
    "Net.apply(init_weights)\n",
    "if torch.cuda.is_available() : \n",
    "    Net = Net.cuda()\n",
    "    print('Model on GPU')\n",
    "    \n",
    "Net.load_state_dict(torch.load('../saved_models/autoencoder2.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr = 5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 20, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "total_step = len(train_dataset) // (batch_size * reqd_len)\n",
    "train_loss_list = list()\n",
    "min_loss = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (x, y, z) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            x = Variable(x).cuda().float()\n",
    "            y = Variable(y).cuda().float()\n",
    "            z = Variable(z).cuda().float()\n",
    "        else : \n",
    "            x = Variable(x).float()\n",
    "            y = Variable(y).float()\n",
    "            z = Variable(z).float()\n",
    "        \n",
    "        x = x.reshape(-1, 1, 100)\n",
    "        y = y.reshape(-1, 1, 100)\n",
    "        z = z.reshape(-1, 1, 100)\n",
    "        \n",
    "        x_, y_, z_ = Net.forward(x, y, z)\n",
    "        \n",
    "        loss0 = criterion(x_, x)\n",
    "        loss1 = criterion(y_, y)\n",
    "        loss2 = criterion(z_, z)\n",
    "        loss = loss0 + loss1 + loss2\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    if train_loss < min_loss : \n",
    "        min_loss = train_loss\n",
    "        torch.save(Net.state_dict() , '../saved_models/autoencoder.pt')\n",
    "        print('Saving model', min_loss)\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbc8813cf28>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = range(53)\n",
    "plt.plot(j, train_loss_list, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying that AutoEncoder has not learnt the identity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[-0.1033, -0.2026,  0.0014,  0.1955,  0.2268],\n",
      "         [-0.0802,  0.1766, -0.0806, -0.0980,  0.0743],\n",
      "         [ 0.0686,  0.2091,  0.0569,  0.1214, -0.0308]],\n",
      "\n",
      "        [[-0.1614,  0.1851,  0.0192,  0.0108,  0.2811],\n",
      "         [ 0.1730,  0.2893,  0.0396, -0.0099,  0.0524],\n",
      "         [-0.0293, -0.2023, -0.0293, -0.2639, -0.1007]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[ 0.1717, -0.3044, -0.2986, -0.0895,  0.0403],\n",
      "         [-0.0380,  0.2184, -0.1598,  0.2515,  0.1688]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[-0.0332, -0.6918, -0.0554, -0.1719, -0.4610]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[-0.3648,  0.2126, -0.2366, -0.0121, -0.3545]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "Net = AutoEncoder()\n",
    "Net.load_state_dict(torch.load('../saved_models/autoencoder2.pt'))\n",
    "Net = Net.eval().cpu()\n",
    "print(Net.encoder[0].weight)\n",
    "print(Net.encoder[2].weight)\n",
    "print(Net.decoder[0].weight)\n",
    "print(Net.decoder[2].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking reconstruction quality visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st and 2nd axis loss :  0.000228373464778997\n",
      "3rd axis loss :  0.0014632847160100937\n",
      "0.0006400104612112045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f28d7b879e8>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Net = Net.eval()\n",
    "x = next(iter(testloader2))\n",
    "y = Net.forward(x.float())\n",
    "loss = criterion(torch.transpose(x, 1, 2).float(), y)\n",
    "\n",
    "x1 = torch.transpose(x, 1, 2)[0][ : 2].float()\n",
    "y1 = y[0][ : 2].float()\n",
    "print('1st and 2nd axis loss : ', criterion(y1, x1).item())\n",
    "x2 = torch.transpose(x, 1, 2)[0][2].float()\n",
    "y2 = y[0][2].float()\n",
    "print('3rd axis loss : ', criterion(y2, x2).item())\n",
    "\n",
    "x = torch.transpose(x, 1, 2)\n",
    "x = x.detach().numpy()\n",
    "y = y.detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "ax[0].plot(x[0][0], 'r')\n",
    "ax[0].plot(y[0][0], 'g')\n",
    "print(loss.item())\n",
    "ax[1].plot(x[0][1], 'r')\n",
    "ax[1].plot(y[0][1], 'g')\n",
    "ax[2].plot(x[0][2], 'r')\n",
    "ax[2].plot(y[0][2], 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruction quality is very much improved compared to using 3 channel autoencoder or using 1 channel data for training autoencoder. Now we can try to train a classifier based on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128100, 8)\n",
      "(15900, 8)\n",
      "(16200, 8)\n"
     ]
    }
   ],
   "source": [
    "reqd_len = 150\n",
    "channels = 3\n",
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, mode = 'test', transform = None):\n",
    "        if mode == 'train' :\n",
    "            self.df = pd.read_csv('../data/train.csv', header = None)\n",
    "        elif mode == 'test' :\n",
    "            self.df = pd.read_csv('../data/test.csv', header = None)\n",
    "        elif mode == 'val' :\n",
    "            self.df = pd.read_csv('../data/val.csv', header = None)\n",
    "        self.transform = transform\n",
    "        print(self.df.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        lab = self.df.iloc[idx : idx + reqd_len, 3 : ].values\n",
    "        ind = np.argmax(np.sum(lab, axis = 0))\n",
    "        label = np.zeros_like(self.df.iloc[0, 3 : ].values)\n",
    "        label = label.astype('float')\n",
    "        label[ind] = 1\n",
    "        x = self.df.iloc[idx : idx + reqd_len, 0].values\n",
    "        y = self.df.iloc[idx : idx + reqd_len, 1].values\n",
    "        z = self.df.iloc[idx : idx + reqd_len, 2].values\n",
    "        x = x.astype('float')\n",
    "        y = y.astype('float')\n",
    "        z = z.astype('float')\n",
    "        assert(x.shape == (reqd_len, ))\n",
    "        assert(y.shape == (reqd_len, ))\n",
    "        assert(z.shape == (reqd_len, ))\n",
    "        assert(label.shape == (5, ))\n",
    "        return x, y, z, label\n",
    "        \n",
    "trainset = IMUDataset(mode = 'train')\n",
    "valset = IMUDataset(mode = 'val')\n",
    "testset = IMUDataset(mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 16\n",
    "batch_size = 16\n",
    "train_indices = [(i * reqd_len) for i in range(len(trainset) // reqd_len)]\n",
    "val_indices = [(i * reqd_len) for i in range(len(valset) // reqd_len)]\n",
    "test_indices = [(i * reqd_len) for i in range(len(testset) // reqd_len)]\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size = train_batch_size, sampler = SubsetRandomSampler(train_indices), drop_last = True)\n",
    "valloader = DataLoader(valset, batch_size = batch_size, sampler = SubsetRandomSampler(val_indices), drop_last = True)\n",
    "testloader = DataLoader(testset, batch_size = batch_size, sampler = SubsetRandomSampler(test_indices), drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading autoencoder saved model\n",
    "Net = AutoEncoder()\n",
    "Net.load_state_dict(torch.load('../saved_models/autoencoder8.pt'), strict = False)\n",
    "# freezing encoders' and decoders' layers\n",
    "Net = Net.cuda()\n",
    "\n",
    "for param in Net.encoder0.parameters() : \n",
    "    param.requires_grad = False\n",
    "for param in Net.encoder1.parameters() : \n",
    "    param.requires_grad = False\n",
    "for param in Net.encoder2.parameters() : \n",
    "    param.requires_grad = False\n",
    "for param in Net.decoder0.parameters() : \n",
    "    param.requires_grad = False\n",
    "for param in Net.decoder1.parameters() : \n",
    "    param.requires_grad = False\n",
    "for param in Net.decoder2.parameters() : \n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr = 1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  53  loss =  1.562229037284851\n",
      "epoch =  0  step =  20  of total steps  53  loss =  1.513242244720459\n",
      "epoch =  0  step =  40  of total steps  53  loss =  1.5499019622802734\n",
      "epoch :  0  /  100  | TL :  1.5173714678242523  | VL :  1.5593128204345703\n",
      "saving model\n",
      "epoch =  1  step =  0  of total steps  53  loss =  1.3422439098358154\n",
      "epoch =  1  step =  20  of total steps  53  loss =  1.3854888677597046\n",
      "epoch =  1  step =  40  of total steps  53  loss =  1.494871973991394\n",
      "epoch :  1  /  100  | TL :  1.4518622519834987  | VL :  1.5335348844528198\n",
      "saving model\n",
      "epoch =  2  step =  0  of total steps  53  loss =  1.6037654876708984\n",
      "epoch =  2  step =  20  of total steps  53  loss =  1.1801064014434814\n",
      "epoch =  2  step =  40  of total steps  53  loss =  1.366023063659668\n",
      "epoch :  2  /  100  | TL :  1.413777859705799  | VL :  1.5698771476745605\n",
      "epoch =  3  step =  0  of total steps  53  loss =  1.259040355682373\n",
      "epoch =  3  step =  20  of total steps  53  loss =  1.487945318222046\n",
      "epoch =  3  step =  40  of total steps  53  loss =  1.2900238037109375\n",
      "epoch :  3  /  100  | TL :  1.370269404267365  | VL :  1.5408649444580078\n",
      "epoch =  4  step =  0  of total steps  53  loss =  1.2478431463241577\n",
      "epoch =  4  step =  20  of total steps  53  loss =  1.3793869018554688\n",
      "epoch =  4  step =  40  of total steps  53  loss =  1.1863030195236206\n",
      "epoch :  4  /  100  | TL :  1.316331483283133  | VL :  1.511387586593628\n",
      "saving model\n",
      "epoch =  5  step =  0  of total steps  53  loss =  1.3500736951828003\n",
      "epoch =  5  step =  20  of total steps  53  loss =  1.1340303421020508\n",
      "epoch =  5  step =  40  of total steps  53  loss =  1.2383983135223389\n",
      "epoch :  5  /  100  | TL :  1.2670826540803009  | VL :  1.5153861045837402\n",
      "epoch =  6  step =  0  of total steps  53  loss =  1.221041202545166\n",
      "epoch =  6  step =  20  of total steps  53  loss =  1.3132190704345703\n",
      "epoch =  6  step =  40  of total steps  53  loss =  1.2574892044067383\n",
      "epoch :  6  /  100  | TL :  1.1841434240341187  | VL :  1.4989408254623413\n",
      "saving model\n",
      "epoch =  7  step =  0  of total steps  53  loss =  1.2967734336853027\n",
      "epoch =  7  step =  20  of total steps  53  loss =  1.1788333654403687\n",
      "epoch =  7  step =  40  of total steps  53  loss =  1.2186568975448608\n",
      "epoch :  7  /  100  | TL :  1.150581344118658  | VL :  1.5379455089569092\n",
      "epoch =  8  step =  0  of total steps  53  loss =  1.2648060321807861\n",
      "epoch =  8  step =  20  of total steps  53  loss =  1.2220778465270996\n",
      "epoch =  8  step =  40  of total steps  53  loss =  1.050782322883606\n",
      "epoch :  8  /  100  | TL :  1.1104608391815762  | VL :  1.5840065479278564\n",
      "epoch =  9  step =  0  of total steps  53  loss =  1.076072096824646\n",
      "epoch =  9  step =  20  of total steps  53  loss =  0.9514167308807373\n",
      "epoch =  9  step =  40  of total steps  53  loss =  1.442236304283142\n",
      "epoch :  9  /  100  | TL :  1.0786735629135709  | VL :  1.5542402267456055\n",
      "epoch =  10  step =  0  of total steps  53  loss =  1.0107712745666504\n",
      "epoch =  10  step =  20  of total steps  53  loss =  1.3037465810775757\n",
      "epoch =  10  step =  40  of total steps  53  loss =  0.9683879613876343\n",
      "epoch :  10  /  100  | TL :  1.0435499065327194  | VL :  1.6224974393844604\n",
      "epoch =  11  step =  0  of total steps  53  loss =  0.7347859144210815\n",
      "epoch =  11  step =  20  of total steps  53  loss =  0.9843415021896362\n",
      "epoch =  11  step =  40  of total steps  53  loss =  0.9937604665756226\n",
      "epoch :  11  /  100  | TL :  0.9929925776877493  | VL :  1.615848422050476\n",
      "epoch =  12  step =  0  of total steps  53  loss =  0.8509995937347412\n",
      "epoch =  12  step =  20  of total steps  53  loss =  0.8653847575187683\n",
      "epoch =  12  step =  40  of total steps  53  loss =  1.0950602293014526\n",
      "epoch :  12  /  100  | TL :  0.9739822306722965  | VL :  1.6109378337860107\n",
      "epoch =  13  step =  0  of total steps  53  loss =  0.8807519674301147\n",
      "epoch =  13  step =  20  of total steps  53  loss =  0.7268614172935486\n",
      "epoch =  13  step =  40  of total steps  53  loss =  0.9422390460968018\n",
      "epoch :  13  /  100  | TL :  0.9493899097982442  | VL :  1.657314658164978\n",
      "epoch =  14  step =  0  of total steps  53  loss =  0.887531042098999\n",
      "epoch =  14  step =  20  of total steps  53  loss =  0.8043631315231323\n",
      "epoch =  14  step =  40  of total steps  53  loss =  0.6816136837005615\n",
      "epoch :  14  /  100  | TL :  0.9316049094470042  | VL :  1.684807300567627\n",
      "epoch =  15  step =  0  of total steps  53  loss =  0.687832772731781\n",
      "epoch =  15  step =  20  of total steps  53  loss =  1.0563724040985107\n",
      "epoch =  15  step =  40  of total steps  53  loss =  0.8052522540092468\n",
      "epoch :  15  /  100  | TL :  0.9126264531657381  | VL :  1.7195959091186523\n",
      "epoch =  16  step =  0  of total steps  53  loss =  0.7675713300704956\n",
      "epoch =  16  step =  20  of total steps  53  loss =  0.9553518295288086\n",
      "epoch =  16  step =  40  of total steps  53  loss =  0.7994775176048279\n",
      "epoch :  16  /  100  | TL :  0.8909096616619038  | VL :  1.701128363609314\n",
      "epoch =  17  step =  0  of total steps  53  loss =  0.7860453128814697\n",
      "epoch =  17  step =  20  of total steps  53  loss =  0.9005343914031982\n",
      "epoch =  17  step =  40  of total steps  53  loss =  0.7680897116661072\n",
      "epoch :  17  /  100  | TL :  0.8810907186202284  | VL :  1.7717547416687012\n",
      "epoch =  18  step =  0  of total steps  53  loss =  0.6764048933982849\n",
      "epoch =  18  step =  20  of total steps  53  loss =  1.006136417388916\n",
      "epoch =  18  step =  40  of total steps  53  loss =  0.8353979587554932\n",
      "epoch :  18  /  100  | TL :  0.8747890321713574  | VL :  1.6923502683639526\n",
      "epoch =  19  step =  0  of total steps  53  loss =  0.9651677012443542\n",
      "epoch =  19  step =  20  of total steps  53  loss =  0.9929072260856628\n",
      "epoch =  19  step =  40  of total steps  53  loss =  0.984287440776825\n",
      "epoch :  19  /  100  | TL :  0.8662514506645922  | VL :  1.726624846458435\n",
      "epoch =  20  step =  0  of total steps  53  loss =  0.9968878030776978\n",
      "epoch =  20  step =  20  of total steps  53  loss =  0.8252177238464355\n",
      "epoch =  20  step =  40  of total steps  53  loss =  0.8811101913452148\n",
      "epoch :  20  /  100  | TL :  0.8558490141382757  | VL :  1.7628406286239624\n",
      "epoch =  21  step =  0  of total steps  53  loss =  0.6233868598937988\n",
      "epoch =  21  step =  20  of total steps  53  loss =  0.64353346824646\n",
      "epoch =  21  step =  40  of total steps  53  loss =  1.0840718746185303\n",
      "epoch :  21  /  100  | TL :  0.8415520843469871  | VL :  1.7529082298278809\n",
      "epoch =  22  step =  0  of total steps  53  loss =  0.6356413960456848\n",
      "epoch =  22  step =  20  of total steps  53  loss =  0.895359992980957\n",
      "epoch =  22  step =  40  of total steps  53  loss =  0.7180753946304321\n",
      "epoch :  22  /  100  | TL :  0.8394655157934945  | VL :  1.7546334266662598\n",
      "epoch =  23  step =  0  of total steps  53  loss =  0.9389235377311707\n",
      "epoch =  23  step =  20  of total steps  53  loss =  0.7374728918075562\n",
      "epoch =  23  step =  40  of total steps  53  loss =  1.1082079410552979\n",
      "epoch :  23  /  100  | TL :  0.8347673056260595  | VL :  1.7453831434249878\n",
      "epoch =  24  step =  0  of total steps  53  loss =  1.0535895824432373\n",
      "epoch =  24  step =  20  of total steps  53  loss =  0.6985441446304321\n",
      "epoch =  24  step =  40  of total steps  53  loss =  0.9415066242218018\n",
      "epoch :  24  /  100  | TL :  0.8315388031725613  | VL :  1.7435029745101929\n",
      "epoch =  25  step =  0  of total steps  53  loss =  0.8462798595428467\n",
      "epoch =  25  step =  20  of total steps  53  loss =  1.025573492050171\n",
      "epoch =  25  step =  40  of total steps  53  loss =  0.7634202837944031\n",
      "epoch :  25  /  100  | TL :  0.8246249489064487  | VL :  1.763018012046814\n",
      "epoch =  26  step =  0  of total steps  53  loss =  0.7183568477630615\n",
      "epoch =  26  step =  20  of total steps  53  loss =  0.5047370195388794\n",
      "epoch =  26  step =  40  of total steps  53  loss =  0.9142575263977051\n",
      "epoch :  26  /  100  | TL :  0.8203186347799482  | VL :  1.7855660915374756\n",
      "epoch =  27  step =  0  of total steps  53  loss =  0.8111528754234314\n",
      "epoch =  27  step =  20  of total steps  53  loss =  0.8075342178344727\n",
      "epoch =  27  step =  40  of total steps  53  loss =  0.964353084564209\n",
      "epoch :  27  /  100  | TL :  0.8159959979777066  | VL :  1.7260608673095703\n",
      "epoch =  28  step =  0  of total steps  53  loss =  0.7513421773910522\n",
      "epoch =  28  step =  20  of total steps  53  loss =  1.0990824699401855\n",
      "epoch =  28  step =  40  of total steps  53  loss =  0.5885872840881348\n",
      "epoch :  28  /  100  | TL :  0.8142609180144544  | VL :  1.8005836009979248\n",
      "epoch =  29  step =  0  of total steps  53  loss =  0.5945371985435486\n",
      "epoch =  29  step =  20  of total steps  53  loss =  1.1045939922332764\n",
      "epoch =  29  step =  40  of total steps  53  loss =  0.646213173866272\n",
      "epoch :  29  /  100  | TL :  0.8153460408156773  | VL :  1.811180830001831\n",
      "epoch =  30  step =  0  of total steps  53  loss =  0.9805440902709961\n",
      "epoch =  30  step =  20  of total steps  53  loss =  0.6501809358596802\n",
      "epoch =  30  step =  40  of total steps  53  loss =  0.8143617510795593\n",
      "epoch :  30  /  100  | TL :  0.8120384992293592  | VL :  1.8040083646774292\n",
      "epoch =  31  step =  0  of total steps  53  loss =  0.6901085376739502\n",
      "epoch =  31  step =  20  of total steps  53  loss =  0.977990984916687\n",
      "epoch =  31  step =  40  of total steps  53  loss =  0.9079579710960388\n",
      "epoch :  31  /  100  | TL :  0.8077122276684023  | VL :  1.7685718536376953\n",
      "epoch =  32  step =  0  of total steps  53  loss =  0.6683129072189331\n",
      "epoch =  32  step =  20  of total steps  53  loss =  0.793328046798706\n",
      "epoch =  32  step =  40  of total steps  53  loss =  0.8036892414093018\n",
      "epoch :  32  /  100  | TL :  0.8075723175732594  | VL :  1.7818386554718018\n",
      "epoch =  33  step =  0  of total steps  53  loss =  0.6901324987411499\n",
      "epoch =  33  step =  20  of total steps  53  loss =  1.0075846910476685\n",
      "epoch =  33  step =  40  of total steps  53  loss =  0.9511731863021851\n",
      "epoch :  33  /  100  | TL :  0.8050567845128617  | VL :  1.779098391532898\n",
      "epoch =  34  step =  0  of total steps  53  loss =  0.8258265852928162\n",
      "epoch =  34  step =  20  of total steps  53  loss =  0.7666913270950317\n",
      "epoch =  34  step =  40  of total steps  53  loss =  0.8325895071029663\n",
      "epoch :  34  /  100  | TL :  0.8014244954541044  | VL :  1.7697423696517944\n",
      "epoch =  35  step =  0  of total steps  53  loss =  0.7514791488647461\n",
      "epoch =  35  step =  20  of total steps  53  loss =  1.069990873336792\n",
      "epoch =  35  step =  40  of total steps  53  loss =  0.5319775938987732\n",
      "epoch :  35  /  100  | TL :  0.8042230786017652  | VL :  1.7300968170166016\n",
      "epoch =  36  step =  0  of total steps  53  loss =  0.6100068688392639\n",
      "epoch =  36  step =  20  of total steps  53  loss =  0.6339036226272583\n",
      "epoch =  36  step =  40  of total steps  53  loss =  0.910280704498291\n",
      "epoch :  36  /  100  | TL :  0.802824967874671  | VL :  1.7397831678390503\n",
      "epoch =  37  step =  0  of total steps  53  loss =  0.758587121963501\n",
      "epoch =  37  step =  20  of total steps  53  loss =  0.7656814455986023\n",
      "epoch =  37  step =  40  of total steps  53  loss =  0.7660402059555054\n",
      "epoch :  37  /  100  | TL :  0.802935890431674  | VL :  1.7734136581420898\n",
      "epoch =  38  step =  0  of total steps  53  loss =  0.9272106885910034\n",
      "epoch =  38  step =  20  of total steps  53  loss =  0.7463254332542419\n",
      "epoch =  38  step =  40  of total steps  53  loss =  0.6119034290313721\n",
      "epoch :  38  /  100  | TL :  0.7995617738309896  | VL :  1.8020758628845215\n",
      "epoch =  39  step =  0  of total steps  53  loss =  0.8148436546325684\n",
      "epoch =  39  step =  20  of total steps  53  loss =  0.8717604875564575\n",
      "epoch =  39  step =  40  of total steps  53  loss =  0.9154813289642334\n",
      "epoch :  39  /  100  | TL :  0.8015884745795772  | VL :  1.8024762868881226\n",
      "epoch =  40  step =  0  of total steps  53  loss =  0.8305586576461792\n",
      "epoch =  40  step =  20  of total steps  53  loss =  0.8481770753860474\n",
      "epoch =  40  step =  40  of total steps  53  loss =  0.7119758129119873\n",
      "epoch :  40  /  100  | TL :  0.8017646321710551  | VL :  1.7243614196777344\n",
      "epoch =  41  step =  0  of total steps  53  loss =  0.8128489851951599\n",
      "epoch =  41  step =  20  of total steps  53  loss =  0.6978422403335571\n",
      "epoch =  41  step =  40  of total steps  53  loss =  0.7748862504959106\n",
      "epoch :  41  /  100  | TL :  0.7977700683305848  | VL :  1.7810672521591187\n",
      "epoch =  42  step =  0  of total steps  53  loss =  0.7317419052124023\n",
      "epoch =  42  step =  20  of total steps  53  loss =  0.7775920629501343\n",
      "epoch =  42  step =  40  of total steps  53  loss =  0.8531941175460815\n",
      "epoch :  42  /  100  | TL :  0.7972931378292587  | VL :  1.7555698156356812\n",
      "epoch =  43  step =  0  of total steps  53  loss =  0.8072113394737244\n",
      "epoch =  43  step =  20  of total steps  53  loss =  0.7197403907775879\n",
      "epoch =  43  step =  40  of total steps  53  loss =  0.5942442417144775\n",
      "epoch :  43  /  100  | TL :  0.7977736991531444  | VL :  1.7699573040008545\n",
      "epoch =  44  step =  0  of total steps  53  loss =  0.7581990957260132\n",
      "epoch =  44  step =  20  of total steps  53  loss =  0.6690628528594971\n",
      "epoch =  44  step =  40  of total steps  53  loss =  0.8117372393608093\n",
      "epoch :  44  /  100  | TL :  0.7994562544912662  | VL :  1.7958297729492188\n",
      "epoch =  45  step =  0  of total steps  53  loss =  0.7720417380332947\n",
      "epoch =  45  step =  20  of total steps  53  loss =  0.8341797590255737\n",
      "epoch =  45  step =  40  of total steps  53  loss =  0.7485288381576538\n",
      "epoch :  45  /  100  | TL :  0.7967765477468383  | VL :  1.8223674297332764\n",
      "epoch =  46  step =  0  of total steps  53  loss =  0.7382259368896484\n",
      "epoch =  46  step =  20  of total steps  53  loss =  0.8145838975906372\n",
      "epoch =  46  step =  40  of total steps  53  loss =  0.8499991297721863\n",
      "epoch :  46  /  100  | TL :  0.7981160024427018  | VL :  1.7622795104980469\n",
      "epoch =  47  step =  0  of total steps  53  loss =  0.7548343539237976\n",
      "epoch =  47  step =  20  of total steps  53  loss =  1.0482699871063232\n",
      "epoch =  47  step =  40  of total steps  53  loss =  0.8551933169364929\n",
      "epoch :  47  /  100  | TL :  0.7989052927718973  | VL :  1.8069647550582886\n",
      "epoch =  48  step =  0  of total steps  53  loss =  0.8825002908706665\n",
      "epoch =  48  step =  20  of total steps  53  loss =  0.5759002566337585\n",
      "epoch =  48  step =  40  of total steps  53  loss =  1.0762956142425537\n",
      "epoch :  48  /  100  | TL :  0.7980921200986179  | VL :  1.7737606763839722\n",
      "epoch =  49  step =  0  of total steps  53  loss =  1.110192894935608\n",
      "epoch =  49  step =  20  of total steps  53  loss =  0.6098642349243164\n",
      "epoch =  49  step =  40  of total steps  53  loss =  0.9038044810295105\n",
      "epoch :  49  /  100  | TL :  0.7942157719495162  | VL :  1.7382726669311523\n",
      "epoch =  50  step =  0  of total steps  53  loss =  0.8541048765182495\n",
      "epoch =  50  step =  20  of total steps  53  loss =  0.9086490869522095\n",
      "epoch =  50  step =  40  of total steps  53  loss =  0.9373102188110352\n",
      "epoch :  50  /  100  | TL :  0.7975245365556681  | VL :  1.7978438138961792\n",
      "epoch =  51  step =  0  of total steps  53  loss =  0.8349825739860535\n",
      "epoch =  51  step =  20  of total steps  53  loss =  0.5677346587181091\n",
      "epoch =  51  step =  40  of total steps  53  loss =  0.8801726698875427\n",
      "epoch :  51  /  100  | TL :  0.7978353455381574  | VL :  1.791156530380249\n",
      "epoch =  52  step =  0  of total steps  53  loss =  1.1623986959457397\n",
      "epoch =  52  step =  20  of total steps  53  loss =  1.1302520036697388\n",
      "epoch =  52  step =  40  of total steps  53  loss =  0.7208143472671509\n",
      "epoch :  52  /  100  | TL :  0.7966564578830071  | VL :  1.7980670928955078\n",
      "epoch =  53  step =  0  of total steps  53  loss =  1.0058432817459106\n",
      "epoch =  53  step =  20  of total steps  53  loss =  0.7388017177581787\n",
      "epoch =  53  step =  40  of total steps  53  loss =  0.7860461473464966\n",
      "epoch :  53  /  100  | TL :  0.7967504870216802  | VL :  1.7229136228561401\n",
      "epoch =  54  step =  0  of total steps  53  loss =  0.9370032548904419\n",
      "epoch =  54  step =  20  of total steps  53  loss =  0.6637675762176514\n",
      "epoch =  54  step =  40  of total steps  53  loss =  0.6912059187889099\n",
      "epoch :  54  /  100  | TL :  0.7954450193441139  | VL :  1.7438135147094727\n",
      "epoch =  55  step =  0  of total steps  53  loss =  0.7454997897148132\n",
      "epoch =  55  step =  20  of total steps  53  loss =  0.798850953578949\n",
      "epoch =  55  step =  40  of total steps  53  loss =  0.6982417106628418\n",
      "epoch :  55  /  100  | TL :  0.7973697073054764  | VL :  1.736093282699585\n",
      "epoch =  56  step =  0  of total steps  53  loss =  0.6501731276512146\n",
      "epoch =  56  step =  20  of total steps  53  loss =  0.7043356895446777\n",
      "epoch =  56  step =  40  of total steps  53  loss =  0.6334700584411621\n",
      "epoch :  56  /  100  | TL :  0.7957915495026786  | VL :  1.8052949905395508\n",
      "epoch =  57  step =  0  of total steps  53  loss =  0.9865972399711609\n",
      "epoch =  57  step =  20  of total steps  53  loss =  0.7979493141174316\n",
      "epoch =  57  step =  40  of total steps  53  loss =  0.594149112701416\n",
      "epoch :  57  /  100  | TL :  0.7969978631667372  | VL :  1.8121765851974487\n",
      "epoch =  58  step =  0  of total steps  53  loss =  0.9814493060112\n",
      "epoch =  58  step =  20  of total steps  53  loss =  0.9388644099235535\n",
      "epoch =  58  step =  40  of total steps  53  loss =  0.755510687828064\n",
      "epoch :  58  /  100  | TL :  0.7983751207027795  | VL :  1.7667640447616577\n",
      "epoch =  59  step =  0  of total steps  53  loss =  0.7073996067047119\n",
      "epoch =  59  step =  20  of total steps  53  loss =  0.715411901473999\n",
      "epoch =  59  step =  40  of total steps  53  loss =  0.6645751595497131\n",
      "epoch :  59  /  100  | TL :  0.797224482275405  | VL :  1.7587536573410034\n",
      "epoch =  60  step =  0  of total steps  53  loss =  0.6177495121955872\n",
      "epoch =  60  step =  20  of total steps  53  loss =  0.7592133283615112\n",
      "epoch =  60  step =  40  of total steps  53  loss =  0.7674428820610046\n",
      "epoch :  60  /  100  | TL :  0.7961766967233622  | VL :  1.8153331279754639\n",
      "epoch =  61  step =  0  of total steps  53  loss =  0.8664392232894897\n",
      "epoch =  61  step =  20  of total steps  53  loss =  0.8718305826187134\n",
      "epoch =  61  step =  40  of total steps  53  loss =  0.8129444122314453\n",
      "epoch :  61  /  100  | TL :  0.7959997766422775  | VL :  1.769850730895996\n",
      "epoch =  62  step =  0  of total steps  53  loss =  0.7763240337371826\n",
      "epoch =  62  step =  20  of total steps  53  loss =  0.7655969858169556\n",
      "epoch =  62  step =  40  of total steps  53  loss =  0.8084300756454468\n",
      "epoch :  62  /  100  | TL :  0.7948035406616499  | VL :  1.7980120182037354\n",
      "epoch =  63  step =  0  of total steps  53  loss =  0.8868433237075806\n",
      "epoch =  63  step =  20  of total steps  53  loss =  0.793768048286438\n",
      "epoch =  63  step =  40  of total steps  53  loss =  0.7958507537841797\n",
      "epoch :  63  /  100  | TL :  0.7974786117391767  | VL :  1.7849304676055908\n",
      "epoch =  64  step =  0  of total steps  53  loss =  0.6925909519195557\n",
      "epoch =  64  step =  20  of total steps  53  loss =  0.6362528204917908\n",
      "epoch =  64  step =  40  of total steps  53  loss =  0.7270369529724121\n",
      "epoch :  64  /  100  | TL :  0.7965095993482841  | VL :  1.8127171993255615\n",
      "epoch =  65  step =  0  of total steps  53  loss =  0.8032688498497009\n",
      "epoch =  65  step =  20  of total steps  53  loss =  0.6636034250259399\n",
      "epoch =  65  step =  40  of total steps  53  loss =  0.5759706497192383\n",
      "epoch :  65  /  100  | TL :  0.796373796912859  | VL :  1.7552646398544312\n",
      "epoch =  66  step =  0  of total steps  53  loss =  0.8918389678001404\n",
      "epoch =  66  step =  20  of total steps  53  loss =  0.5803279280662537\n",
      "epoch =  66  step =  40  of total steps  53  loss =  0.7247082591056824\n",
      "epoch :  66  /  100  | TL :  0.7968011498451233  | VL :  1.7980469465255737\n",
      "epoch =  67  step =  0  of total steps  53  loss =  0.7744611501693726\n",
      "epoch =  67  step =  20  of total steps  53  loss =  0.8605378866195679\n",
      "epoch =  67  step =  40  of total steps  53  loss =  0.7306076288223267\n",
      "epoch :  67  /  100  | TL :  0.7978946718404878  | VL :  1.7627623081207275\n",
      "epoch =  68  step =  0  of total steps  53  loss =  0.8236185908317566\n",
      "epoch =  68  step =  20  of total steps  53  loss =  0.9398541450500488\n",
      "epoch =  68  step =  40  of total steps  53  loss =  0.7830781936645508\n",
      "epoch :  68  /  100  | TL :  0.7974128070867287  | VL :  1.7807215452194214\n",
      "epoch =  69  step =  0  of total steps  53  loss =  0.6450594067573547\n",
      "epoch =  69  step =  20  of total steps  53  loss =  0.7196307182312012\n",
      "epoch =  69  step =  40  of total steps  53  loss =  0.994590699672699\n",
      "epoch :  69  /  100  | TL :  0.7952192245789294  | VL :  1.7775806188583374\n",
      "epoch =  70  step =  0  of total steps  53  loss =  0.761938750743866\n",
      "epoch =  70  step =  20  of total steps  53  loss =  0.7426208257675171\n",
      "epoch =  70  step =  40  of total steps  53  loss =  0.7547246217727661\n",
      "epoch :  70  /  100  | TL :  0.7942480917246837  | VL :  1.7584885358810425\n",
      "epoch =  71  step =  0  of total steps  53  loss =  0.7769087553024292\n",
      "epoch =  71  step =  20  of total steps  53  loss =  0.8009669780731201\n",
      "epoch =  71  step =  40  of total steps  53  loss =  0.8413451910018921\n",
      "epoch :  71  /  100  | TL :  0.7966298415975751  | VL :  1.8092074394226074\n",
      "epoch =  72  step =  0  of total steps  53  loss =  0.6373572945594788\n",
      "epoch =  72  step =  20  of total steps  53  loss =  0.7690272331237793\n",
      "epoch =  72  step =  40  of total steps  53  loss =  0.7289595007896423\n",
      "epoch :  72  /  100  | TL :  0.7978308110866906  | VL :  1.7881754636764526\n",
      "epoch =  73  step =  0  of total steps  53  loss =  0.9944941401481628\n",
      "epoch =  73  step =  20  of total steps  53  loss =  0.8307440280914307\n",
      "epoch =  73  step =  40  of total steps  53  loss =  0.7428336143493652\n",
      "epoch :  73  /  100  | TL :  0.7975669930566032  | VL :  1.7920472621917725\n",
      "epoch =  74  step =  0  of total steps  53  loss =  0.992548942565918\n",
      "epoch =  74  step =  20  of total steps  53  loss =  0.7934160232543945\n",
      "epoch =  74  step =  40  of total steps  53  loss =  0.6120578050613403\n",
      "epoch :  74  /  100  | TL :  0.7976112354476497  | VL :  1.819291353225708\n",
      "epoch =  75  step =  0  of total steps  53  loss =  0.6368828415870667\n",
      "epoch =  75  step =  20  of total steps  53  loss =  1.2582225799560547\n",
      "epoch =  75  step =  40  of total steps  53  loss =  0.8311650156974792\n",
      "epoch :  75  /  100  | TL :  0.7934195050653422  | VL :  1.791792631149292\n",
      "epoch =  76  step =  0  of total steps  53  loss =  0.860318660736084\n",
      "epoch =  76  step =  20  of total steps  53  loss =  0.8634695410728455\n",
      "epoch =  76  step =  40  of total steps  53  loss =  0.8606570959091187\n",
      "epoch :  76  /  100  | TL :  0.7969550782779478  | VL :  1.810243010520935\n",
      "epoch =  77  step =  0  of total steps  53  loss =  0.953039824962616\n",
      "epoch =  77  step =  20  of total steps  53  loss =  0.7313398122787476\n",
      "epoch =  77  step =  40  of total steps  53  loss =  0.7650140523910522\n",
      "epoch :  77  /  100  | TL :  0.7991455321042042  | VL :  1.813890814781189\n",
      "epoch =  78  step =  0  of total steps  53  loss =  0.9897003173828125\n",
      "epoch =  78  step =  20  of total steps  53  loss =  0.7024483680725098\n",
      "epoch =  78  step =  40  of total steps  53  loss =  0.7339693307876587\n",
      "epoch :  78  /  100  | TL :  0.7964981546941793  | VL :  1.7923588752746582\n",
      "epoch =  79  step =  0  of total steps  53  loss =  0.9366330504417419\n",
      "epoch =  79  step =  20  of total steps  53  loss =  0.8680128455162048\n",
      "epoch =  79  step =  40  of total steps  53  loss =  0.8849881887435913\n",
      "epoch :  79  /  100  | TL :  0.7959048039508316  | VL :  1.8400046825408936\n",
      "epoch =  80  step =  0  of total steps  53  loss =  0.7700220346450806\n",
      "epoch =  80  step =  20  of total steps  53  loss =  0.6223301887512207\n",
      "epoch =  80  step =  40  of total steps  53  loss =  1.0574676990509033\n",
      "epoch :  80  /  100  | TL :  0.792147049364054  | VL :  1.7768447399139404\n",
      "epoch =  81  step =  0  of total steps  53  loss =  0.7202309370040894\n",
      "epoch =  81  step =  20  of total steps  53  loss =  0.9780774116516113\n",
      "epoch =  81  step =  40  of total steps  53  loss =  0.9171454310417175\n",
      "epoch :  81  /  100  | TL :  0.7975243374986468  | VL :  1.8122801780700684\n",
      "epoch =  82  step =  0  of total steps  53  loss =  0.7418448328971863\n",
      "epoch =  82  step =  20  of total steps  53  loss =  0.9371442198753357\n",
      "epoch =  82  step =  40  of total steps  53  loss =  1.106461524963379\n",
      "epoch :  82  /  100  | TL :  0.7981345147456763  | VL :  1.8452229499816895\n",
      "epoch =  83  step =  0  of total steps  53  loss =  0.8132976293563843\n",
      "epoch =  83  step =  20  of total steps  53  loss =  0.7650536298751831\n",
      "epoch =  83  step =  40  of total steps  53  loss =  0.9766781330108643\n",
      "epoch :  83  /  100  | TL :  0.7962124055286623  | VL :  1.7883286476135254\n",
      "epoch =  84  step =  0  of total steps  53  loss =  0.7104970812797546\n",
      "epoch =  84  step =  20  of total steps  53  loss =  0.683497428894043\n",
      "epoch =  84  step =  40  of total steps  53  loss =  0.7594239711761475\n",
      "epoch :  84  /  100  | TL :  0.7955479498179454  | VL :  1.82956862449646\n",
      "epoch =  85  step =  0  of total steps  53  loss =  0.7552062273025513\n",
      "epoch =  85  step =  20  of total steps  53  loss =  0.7304631471633911\n",
      "epoch =  85  step =  40  of total steps  53  loss =  0.8976495265960693\n",
      "epoch :  85  /  100  | TL :  0.7960536198795967  | VL :  1.8506593704223633\n",
      "epoch =  86  step =  0  of total steps  53  loss =  0.9857778549194336\n",
      "epoch =  86  step =  20  of total steps  53  loss =  0.9046306610107422\n",
      "epoch =  86  step =  40  of total steps  53  loss =  0.8048384189605713\n",
      "epoch :  86  /  100  | TL :  0.7943087051499564  | VL :  1.818336844444275\n",
      "epoch =  87  step =  0  of total steps  53  loss =  0.7896771430969238\n",
      "epoch =  87  step =  20  of total steps  53  loss =  0.824786365032196\n",
      "epoch =  87  step =  40  of total steps  53  loss =  0.7689385414123535\n",
      "epoch :  87  /  100  | TL :  0.7965606214865198  | VL :  1.7301782369613647\n",
      "epoch =  88  step =  0  of total steps  53  loss =  0.8579992055892944\n",
      "epoch =  88  step =  20  of total steps  53  loss =  0.6510627269744873\n",
      "epoch =  88  step =  40  of total steps  53  loss =  0.8793150186538696\n",
      "epoch :  88  /  100  | TL :  0.7954654423695691  | VL :  1.8060811758041382\n",
      "epoch =  89  step =  0  of total steps  53  loss =  0.7298603057861328\n",
      "epoch =  89  step =  20  of total steps  53  loss =  0.879705548286438\n",
      "epoch =  89  step =  40  of total steps  53  loss =  0.897498607635498\n",
      "epoch :  89  /  100  | TL :  0.7987159085723589  | VL :  1.7865540981292725\n",
      "epoch =  90  step =  0  of total steps  53  loss =  0.6717349290847778\n",
      "epoch =  90  step =  20  of total steps  53  loss =  0.9647575616836548\n",
      "epoch =  90  step =  40  of total steps  53  loss =  0.6849374771118164\n",
      "epoch :  90  /  100  | TL :  0.7969740415519139  | VL :  1.7961597442626953\n",
      "epoch =  91  step =  0  of total steps  53  loss =  0.9540898203849792\n",
      "epoch =  91  step =  20  of total steps  53  loss =  0.7651801109313965\n",
      "epoch =  91  step =  40  of total steps  53  loss =  0.8129677176475525\n",
      "epoch :  91  /  100  | TL :  0.7972118809538068  | VL :  1.8430488109588623\n",
      "epoch =  92  step =  0  of total steps  53  loss =  0.8074166178703308\n",
      "epoch =  92  step =  20  of total steps  53  loss =  0.8407682180404663\n",
      "epoch =  92  step =  40  of total steps  53  loss =  0.8384578227996826\n",
      "epoch :  92  /  100  | TL :  0.7973111935381619  | VL :  1.787061095237732\n",
      "epoch =  93  step =  0  of total steps  53  loss =  0.8063692450523376\n",
      "epoch =  93  step =  20  of total steps  53  loss =  0.7388864755630493\n",
      "epoch =  93  step =  40  of total steps  53  loss =  0.8429204821586609\n",
      "epoch :  93  /  100  | TL :  0.7946498135350785  | VL :  1.8190929889678955\n",
      "epoch =  94  step =  0  of total steps  53  loss =  0.8963648676872253\n",
      "epoch =  94  step =  20  of total steps  53  loss =  0.7210702300071716\n",
      "epoch =  94  step =  40  of total steps  53  loss =  0.886042058467865\n",
      "epoch :  94  /  100  | TL :  0.7962514848079322  | VL :  1.7541382312774658\n",
      "epoch =  95  step =  0  of total steps  53  loss =  0.6920912265777588\n",
      "epoch =  95  step =  20  of total steps  53  loss =  0.8911935687065125\n",
      "epoch =  95  step =  40  of total steps  53  loss =  0.9107941389083862\n",
      "epoch :  95  /  100  | TL :  0.7972888046840452  | VL :  1.7458853721618652\n",
      "epoch =  96  step =  0  of total steps  53  loss =  0.8989631533622742\n",
      "epoch =  96  step =  20  of total steps  53  loss =  0.7562589645385742\n",
      "epoch =  96  step =  40  of total steps  53  loss =  0.8797721266746521\n",
      "epoch :  96  /  100  | TL :  0.7976295621889942  | VL :  1.7540401220321655\n",
      "epoch =  97  step =  0  of total steps  53  loss =  0.7741486430168152\n",
      "epoch =  97  step =  20  of total steps  53  loss =  0.6058695316314697\n",
      "epoch =  97  step =  40  of total steps  53  loss =  0.6493162512779236\n",
      "epoch :  97  /  100  | TL :  0.7929467851260923  | VL :  1.723667860031128\n",
      "epoch =  98  step =  0  of total steps  53  loss =  0.7262647151947021\n",
      "epoch =  98  step =  20  of total steps  53  loss =  0.6372025012969971\n",
      "epoch =  98  step =  40  of total steps  53  loss =  0.5443316698074341\n",
      "epoch :  98  /  100  | TL :  0.7977914214134216  | VL :  1.8378223180770874\n",
      "epoch =  99  step =  0  of total steps  53  loss =  0.5239824056625366\n",
      "epoch =  99  step =  20  of total steps  53  loss =  0.8234103918075562\n",
      "epoch =  99  step =  40  of total steps  53  loss =  0.6155709028244019\n",
      "epoch :  99  /  100  | TL :  0.795736164416907  | VL :  1.771073818206787\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "total_step = len(trainset) // (train_batch_size * 150)\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (x, y, z, labels) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            x = Variable(x).cuda().float()\n",
    "            y = Variable(y).cuda().float()\n",
    "            z = Variable(z).cuda().float()\n",
    "            labels = Variable(labels).cuda()\n",
    "        else : \n",
    "            x = Variable(x).float()\n",
    "            y = Variable(y).float()\n",
    "            z = Variable(z).float()\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        _, target = torch.max(labels, 1)\n",
    "        \n",
    "        x = x.reshape(-1, 1, 150)\n",
    "        y = y.reshape(-1, 1, 150)\n",
    "        z = z.reshape(-1, 1, 150)\n",
    "        \n",
    "        x_pred, y_pred, z_pred = Net.forward(x, y, z, classify = True)\n",
    "        \n",
    "#         loss = criterion((x_pred + y_pred + z_pred) / 3, target)\n",
    "        loss0 = criterion(x_pred, target)\n",
    "        loss1 = criterion(y_pred, target)\n",
    "        loss2 = criterion(z_pred, target)      \n",
    "        loss = (loss0 + loss1 + loss2) / 3\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (x, y, z, labels) in enumerate(valloader) :\n",
    "            if torch.cuda.is_available():\n",
    "                x = Variable(x).cuda().float()\n",
    "                y = Variable(y).cuda().float()\n",
    "                z = Variable(z).cuda().float()\n",
    "                labels = Variable(labels).cuda()\n",
    "            else : \n",
    "                x = Variable(x).float()\n",
    "                y = Variable(y).float()\n",
    "                z = Variable(z).float()\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "            _, target = torch.max(labels, 1)\n",
    "            \n",
    "            x = x.reshape(-1, 1, 150)\n",
    "            y = y.reshape(-1, 1, 150)\n",
    "            z = z.reshape(-1, 1, 150)\n",
    "            \n",
    "            # Forward pass\n",
    "            x_pred, y_pred, z_pred = Net.forward(x, y, z, classify = True)\n",
    "              \n",
    "            loss0 = criterion(x_pred, target)\n",
    "            loss1 = criterion(y_pred, target)\n",
    "            loss2 = criterion(z_pred, target)\n",
    "            loss = (loss0 + loss1 + loss2) / 3\n",
    "\n",
    "#             loss = criterion((x_pred + y_pred + z_pred) / 3, target)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), '../saved_models/autoencoder_classifier3.pt')\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd0fd57f6a0>,\n",
       " <matplotlib.lines.Line2D at 0x7fd0fd57f7f0>]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = np.arange(100)\n",
    "plt.plot(j, train_loss_list, 'r', j, val_loss_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_accuracy(dataloader, Net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (x, y, z, labels) in enumerate(dataloader):\n",
    "        x = Variable(x).float()\n",
    "        y = Variable(y).float()\n",
    "        z = Variable(z).float()\n",
    "        labels = Variable(labels).float()\n",
    "        x = x.reshape(-1, 1, 150)\n",
    "        y = y.reshape(-1, 1, 150)\n",
    "        z = z.reshape(-1, 1, 150)\n",
    "        x_pred, y_pred, z_pred = Net(x, y, z, classify = True)\n",
    "        outputs = (x_pred + y_pred + z_pred) / 3\n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.numpy()\n",
    "        pred_ind = pred_ind.data.numpy()\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net = Net.cpu().eval()\n",
    "# _get_accuracy(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7983490566037735\n",
      "0.4270833333333333\n",
      "0.375\n"
     ]
    }
   ],
   "source": [
    "print(_get_accuracy(trainloader, Net))\n",
    "print(_get_accuracy(testloader, Net))\n",
    "print(_get_accuracy(valloader, Net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5860849056603774\n",
      "0.375\n",
      "0.3958333333333333\n"
     ]
    }
   ],
   "source": [
    "# Loading autoencoder saved model\n",
    "Net = AutoEncoder()\n",
    "Net.load_state_dict(torch.load('../saved_models/autoencoder_classifier3.pt'), strict = False)\n",
    "print(_get_accuracy(trainloader, Net))\n",
    "print(_get_accuracy(testloader, Net))\n",
    "print(_get_accuracy(valloader, Net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying that encoder and decoder weights remained frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[ 0.2462, -0.3214, -0.1736, -0.7853, -0.6094]]])\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0662, -0.2246, -0.5446, -0.4810,  0.0476]]])\n",
      "Parameter containing:\n",
      "tensor([[[ 0.1591, -0.6918, -0.3941, -0.3774,  0.1053]]])\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0923, -0.2416, -0.0143,  0.0131, -0.5077]]])\n",
      "Parameter containing:\n",
      "tensor([[[-0.0565, -0.3281,  0.3196,  0.4665,  0.3597]]])\n",
      "Parameter containing:\n",
      "tensor([[[-0.1202, -0.0430, -0.6723, -0.3769, -0.3517]]])\n",
      "Parameter containing:\n",
      "tensor([[[-0.0884,  0.0816, -0.5897, -0.3055, -0.2410]]])\n",
      "Parameter containing:\n",
      "tensor([[[-0.1872, -0.1554,  0.3229,  0.4877,  0.3021]]])\n",
      "Parameter containing:\n",
      "tensor([[[-0.1684,  0.3523,  0.0530,  0.5104, -0.1104]]])\n",
      "Parameter containing:\n",
      "tensor([[[ 0.1143, -0.1964, -0.4806, -0.6028, -0.4836]]])\n",
      "Parameter containing:\n",
      "tensor([[[-0.2961,  0.3455, -0.1918,  0.5298,  0.3771]]])\n",
      "Parameter containing:\n",
      "tensor([[[-0.3689, -0.4148, -0.3165, -0.1430, -0.2685]]])\n"
     ]
    }
   ],
   "source": [
    "print(Net.encoder0[0].weight)\n",
    "print(Net.encoder0[2].weight)\n",
    "print(Net.decoder0[0].weight)\n",
    "print(Net.decoder0[2].weight)\n",
    "print(Net.encoder1[0].weight)\n",
    "print(Net.encoder1[2].weight)\n",
    "print(Net.decoder1[0].weight)\n",
    "print(Net.decoder1[2].weight)\n",
    "print(Net.encoder2[0].weight)\n",
    "print(Net.encoder2[2].weight)\n",
    "print(Net.decoder2[0].weight)\n",
    "print(Net.decoder2[2].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the encoded features and save them into a `NumPy` array for using with `sklearn`\n",
    "So, we reload the data used for the autoencoder training part alongwith the labels, and use a similar loop (as in training of autoencoder) to compute the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128100, 8)\n",
      "(16200, 8)\n"
     ]
    }
   ],
   "source": [
    "reqd_len = 150\n",
    "channels = 1\n",
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, mode = 'test', transform = None):\n",
    "        if mode == 'train' : \n",
    "            self.df = pd.read_csv('../data/train.csv', header = None)\n",
    "        elif mode == 'test' : \n",
    "            self.df = pd.read_csv('../data/test.csv', header = None)\n",
    "        self.transform = transform\n",
    "        print(self.df.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        lab = self.df.iloc[idx : idx + reqd_len, 3 : ].values\n",
    "        ind = np.argmax(np.sum(lab, axis = 0))\n",
    "        x = self.df.iloc[idx : idx + reqd_len, 0].values\n",
    "        y = self.df.iloc[idx : idx + reqd_len, 1].values\n",
    "        z = self.df.iloc[idx : idx + reqd_len, 2].values\n",
    "        x = x.astype('float')\n",
    "        y = y.astype('float')\n",
    "        z = z.astype('float')\n",
    "        assert(x.shape == (reqd_len, ))\n",
    "        assert(x.shape == (reqd_len, ))\n",
    "        assert(x.shape == (reqd_len, ))\n",
    "        return x, y, z, ind\n",
    "        \n",
    "train_dataset = IMUDataset(mode = 'train')\n",
    "test_dataset = IMUDataset(mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_indices = [(i * reqd_len) for i in range(len(train_dataset) // reqd_len)]\n",
    "test_indices = [(i * reqd_len) for i in range(len(test_dataset) // reqd_len)]\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size = batch_size, sampler = SubsetRandomSampler(train_indices), drop_last = True)\n",
    "testloader = DataLoader(test_dataset, batch_size = batch_size, sampler = SubsetRandomSampler(test_indices), drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = AutoEncoder()\n",
    "Net.load_state_dict(torch.load('../saved_models/autoencoder8.pt'))\n",
    "Net = Net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_features = np.zeros((len(trainloader), 142))\n",
    "y_train_features = np.zeros((len(trainloader), 142))\n",
    "z_train_features = np.zeros((len(trainloader), 142))\n",
    "train_labels = np.zeros(len(trainloader))\n",
    "for i, (x, y, z, label) in enumerate(trainloader) :\n",
    "    x = Variable(x).float()\n",
    "    y = Variable(y).float()\n",
    "    z = Variable(z).float()\n",
    "    label = label.numpy()\n",
    "    \n",
    "    x = x.reshape(-1, 1, 150)\n",
    "    y = y.reshape(-1, 1, 150)\n",
    "    z = z.reshape(-1, 1, 150)\n",
    "\n",
    "    x_, y_, z_ = Net.forward(x, y, z, encode = True)\n",
    "    \n",
    "    x_ = x_.reshape(x_.shape[2]).detach().numpy()\n",
    "    y_ = y_.reshape(y_.shape[2]).detach().numpy()\n",
    "    z_ = z_.reshape(z_.shape[2]).detach().numpy()\n",
    "    \n",
    "    # Saving the features into NumPy arrays\n",
    "    x_train_features[i] = x_\n",
    "    y_train_features[i] = y_\n",
    "    z_train_features[i] = z_\n",
    "    \n",
    "    train_labels[i] = label\n",
    "    \n",
    "x_test_features = np.zeros((len(testloader), 142))\n",
    "y_test_features = np.zeros((len(testloader), 142))\n",
    "z_test_features = np.zeros((len(testloader), 142))\n",
    "test_labels = np.zeros(len(testloader))\n",
    "for i, (x, y, z, label) in enumerate(testloader) :\n",
    "    x = Variable(x).float()\n",
    "    y = Variable(y).float()\n",
    "    z = Variable(z).float()\n",
    "    label = label.numpy()\n",
    "\n",
    "    x = x.reshape(-1, 1, 150)\n",
    "    y = y.reshape(-1, 1, 150)\n",
    "    z = z.reshape(-1, 1, 150)\n",
    "\n",
    "    x_, y_, z_ = Net.forward(x, y, z, encode = True)\n",
    "    \n",
    "    x_ = x_.reshape(x_.shape[2]).detach().numpy()\n",
    "    y_ = y_.reshape(y_.shape[2]).detach().numpy()\n",
    "    z_ = z_.reshape(z_.shape[2]).detach().numpy()\n",
    "    \n",
    "    # Saving the features into NumPy arrays\n",
    "    x_test_features[i] = x_\n",
    "    y_test_features[i] = y_\n",
    "    z_test_features[i] = z_\n",
    "    \n",
    "    test_labels[i] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we have the features and labels as `NumPy` arrays, so we can use `sklearn` to train a traditional ML classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.naive_bayes\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, SVMSMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(854, 426)\n",
      "(108, 426)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.concatenate((x_train_features, y_train_features, z_train_features), axis = 1)\n",
    "x_test = np.concatenate((x_test_features, y_test_features, z_test_features), axis = 1)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equalizing classes using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1.0: 343, 2.0: 343, 3.0: 343, 0.0: 343, 4.0: 343})\n",
      "float64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(sampling_strategy = 'not majority')\n",
    "x_train_norm, y_train = sm.fit_resample(x_train, train_labels)\n",
    "print(Counter(y_train))\n",
    "print(y_train.dtype)\n",
    "y_train = y_train.astype(int)\n",
    "print(y_train.dtype)\n",
    "x_test_norm = x_test\n",
    "y_test = test_labels.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  0  2  9  2]\n",
      " [ 0  0  1 16  2]\n",
      " [ 1  2 11  5  4]\n",
      " [ 0  1  5 24  3]\n",
      " [ 0  0  2 13  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.13      0.22        15\n",
      "           1       0.00      0.00      0.00        19\n",
      "           2       0.52      0.48      0.50        23\n",
      "           3       0.36      0.73      0.48        33\n",
      "           4       0.21      0.17      0.19        18\n",
      "\n",
      "    accuracy                           0.37       108\n",
      "   macro avg       0.35      0.30      0.28       108\n",
      "weighted avg       0.35      0.37      0.32       108\n",
      "\n",
      "[[343   0   0   0   0]\n",
      " [  0 342   0   0   1]\n",
      " [  1   0 339   1   2]\n",
      " [  0   3   2 336   2]\n",
      " [  0   0   1   0 342]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       343\n",
      "           1       0.99      1.00      0.99       343\n",
      "           2       0.99      0.99      0.99       343\n",
      "           3       1.00      0.98      0.99       343\n",
      "           4       0.99      1.00      0.99       343\n",
      "\n",
      "    accuracy                           0.99      1715\n",
      "   macro avg       0.99      0.99      0.99      1715\n",
      "weighted avg       0.99      0.99      0.99      1715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_lin = RandomForestClassifier(n_estimators = 300)\n",
    "svm_lin.fit(x_train_norm, y_train)\n",
    "y_pred = svm_lin.predict(x_test_norm)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "y_pred = svm_lin.predict(x_train_norm)\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even Random Forest Classifier overfits the features. So, maybe there isn't enough distinction between the various activity classes, so we can try to merge some classes to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
